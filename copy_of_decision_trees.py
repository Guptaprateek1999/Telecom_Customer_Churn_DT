# -*- coding: utf-8 -*-
"""Copy of Decision_trees.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bbxtbbW7d4ewDHiqaFh-hwG-ZMj9fmUI
"""

import pandas as pd
import numpy as np

df = pd.read_csv('/content/Telecom_Customer_Churn.csv')

df.head(5)

df.shape

df.columns

df = df.drop(['customerID'], axis = 1)
df.head()

for i in df.columns:
  if df[i].dtype =='object':
    print(pd.unique(df[i]))

df.dtypes

df.TotalCharges = pd.to_numeric(df.TotalCharges, errors='coerce')
df.dtypes

df[np.isnan(df['TotalCharges'])]

df[df['tenure'] == 0].index

df.drop(labels=df[df['tenure'] == 0].index, axis=0, inplace=True)
df[df['tenure'] == 0].index

df.fillna(df["TotalCharges"].mean())

df.isnull().sum()

df["SeniorCitizen"]= df["SeniorCitizen"].map({0: "No", 1: "Yes"})
df.head()

df["InternetService"].describe(include=['object', 'bool'])

numerical_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']
df[numerical_cols].describe()

from sklearn import metrics
from sklearn.metrics import recall_score, confusion_matrix, precision_score, f1_score, accuracy_score,classification_report

from sklearn.preprocessing import LabelEncoder
def object_to_int(dataframe_):
    if dataframe_.dtype=='object':
        dataframe_ = LabelEncoder().fit_transform(dataframe_)
    return dataframe_

df.dtypes

df = df.apply(lambda x: object_to_int(x))
df.head()

df.corr()['Churn'].sort_values(ascending = False)

X = df.drop(columns = ['Churn'])
y = df['Churn'].values

num_cols = ["tenure", 'MonthlyCharges', 'TotalCharges']

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.30, random_state = 40, stratify=y)

from sklearn.preprocessing import StandardScaler
df_std = pd.DataFrame(StandardScaler().fit_transform(df[num_cols].astype('float64')),
                       columns=num_cols)
scaler= StandardScaler()

X_train[num_cols] = scaler.fit_transform(X_train[num_cols])
X_test[num_cols] = scaler.transform(X_test[num_cols])

from sklearn.tree import DecisionTreeClassifier
dt_model = DecisionTreeClassifier(criterion = 'entropy' )
dt_model.fit(X_train, y_train)
pred=dt_model.predict(X_test)
from sklearn.metrics import accuracy_score
accuracy_score(y_test, pred)

from sklearn import tree
import matplotlib.pyplot as plt
plt.figure(figsize=(15,10))
tree.plot_tree(dt_model,filled=True)

from sklearn.model_selection import GridSearchCV

# hyperparameters to tune
tuned_parameters = [{'criterion':['gini', 'entropy'],

                     'max_leaf_nodes': range(5,25)}] # hyperparameters to tune

clf_D = GridSearchCV(DecisionTreeClassifier(), tuned_parameters,
                   verbose=1, n_jobs=-1) # grid search model
clf_D.fit(X_train, y_train) # evaluate hyper-parameters

print("\nBest parameters found:")
print(clf_D.best_params_) # best hyperparameter balues

criterion = 'gini'
max_leaf_nodes = 18
# Train and test model
good_model_D = DecisionTreeClassifier(criterion=criterion,
                                    max_leaf_nodes=max_leaf_nodes) # create model
print(good_model_D) # display model parameters
good_model_D.fit(X_train, y_train) # train model
pred_D = good_model_D.predict(X_test) # predicted output for test examples
print("Results on test data")
acc_D = accuracy_score(y_test, pred_D) # accuracy on test examples
print(f'Test accuracy = {acc_D: .4f}') # round to 4 decimal places
print("Confusion matrix (Rows actual, Columns predicted):")
print(pd.DataFrame(confusion_matrix(y_test, pred_D)))

"""Post Pruning"""

path = dt_model.cost_complexity_pruning_path(X_train, y_train)
ccp_alphas, impurities = path.ccp_alphas, path.impurities

ccp_alphas

dt_models = []
for ccp_alpha in ccp_alphas:
    dt_model_1= DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)
    dt_model_1.fit(X_train, y_train)
    dt_models.append(dt_model_1)
print("Number of nodes in the last tree is: {} with ccp_alpha: {}".format(
      dt_models[-1].tree_.node_count, ccp_alphas[-1]))

from matplotlib.figure import Figure
train_scores = [ dt_model_1.score(X_train, y_train) for  dt_model_1 in dt_models]
test_scores = [ dt_model_1.score(X_test, y_test) for  dt_model_1 in dt_models]

fig, ax = plt.subplots()
plt.figure(figsize=(15,10))
ax.set_xlabel("alpha")
ax.set_ylabel("accuracy")
ax.set_title("Accuracy vs alpha for training and testing sets")
ax.plot(ccp_alphas, train_scores, marker='o', label="train",
        drawstyle="steps-post")
ax.plot(ccp_alphas, test_scores, marker='o', label="test",
        drawstyle="steps-post")
ax.legend()
plt.show()

dt_model_1 = DecisionTreeClassifier(random_state=0, ccp_alpha=0.001)
dt_model_1.fit(X_train,y_train)

pred=dt_model_1.predict(X_test)
from sklearn.metrics import accuracy_score
accuracy_score(y_test, pred)

from sklearn import tree
plt.figure(figsize=(15,10))
tree.plot_tree(dt_model_1,filled=True)

"""Pre Pruning"""

# Preprunning
parameter={
 'criterion':['gini','entropy','log_loss'],
  'splitter':['best','random'],
  'max_depth':[1,2,3,4,5],
  'max_features':['auto', 'sqrt', 'log2']

}

treemodel=DecisionTreeClassifier()
dt_model=GridSearchCV(treemodel,param_grid=parameter,cv=5,scoring='accuracy')
dt_model.fit(X_train,y_train)

dt_model.best_params_

y_pred=dt_model.predict(X_test)

score=accuracy_score(y_pred,y_test)
score